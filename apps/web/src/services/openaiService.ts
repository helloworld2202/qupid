import OpenAI from "openai"
import { Message, ConversationAnalysis, RealtimeFeedback } from "@qupid/core"

// Use environment variable for API key
const apiKey = process.env.OPENAI_API_KEY
if (!apiKey) {
  console.warn(
    "OPENAI_API_KEY environment variable not set. " +
      "Using a placeholder. AI functionality will be disabled. " +
      "Please provide your OpenAI API key."
  )
}

const openai = apiKey ? new OpenAI({ 
  apiKey,
  dangerouslyAllowBrowser: true // Note: In production, API calls should be made from backend
}) : null

// Default model is GPT-4o-mini for cost efficiency
const defaultModel = "gpt-4o-mini"

// Chat session management
interface ChatSession {
  messages: OpenAI.Chat.ChatCompletionMessageParam[]
  systemInstruction: string
}

const chatSessions = new Map<string, ChatSession>()

export const createChatSession = (systemInstruction: string): string => {
  const sessionId = Math.random().toString(36).substring(7)
  chatSessions.set(sessionId, {
    systemInstruction,
    messages: [
      {
        role: "system",
        content: `${systemInstruction} Keep your responses concise, natural, and engaging, like a real chat conversation.`
      }
    ]
  })
  return sessionId
}

export const sendMessageToAI = async (
  sessionId: string,
  message: string
): Promise<string> => {
  if (!openai) {
    return "AI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
  }

  const session = chatSessions.get(sessionId)
  if (!session) {
    return "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”."
  }

  try {
    // Add user message to session
    session.messages.push({ role: "user", content: message })

    const response = await openai.chat.completions.create({
      model: defaultModel,
      messages: session.messages,
      temperature: 0.8,
      max_tokens: 500
    })

    const aiResponse = response.choices[0]?.message?.content || "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    // Add AI response to session
    session.messages.push({ role: "assistant", content: aiResponse })
    
    return aiResponse
  } catch (error) {
    console.error("Error sending message to AI:", error)
    return "ì£„ì†¡í•´ìš”, ì§€ê¸ˆì€ ë‹µë³€í•˜ê¸° ì–´ë µë„¤ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
  }
}

export const analyzeConversation = async (
  conversation: Message[]
): Promise<ConversationAnalysis | null> => {
  if (!openai) return null

  const conversationText = conversation
    .map((msg) => `${msg.sender === "user" ? "ë‚˜" : "ìƒëŒ€"}: ${msg.text}`)
    .join("\n")

  const prompt = `
    ë‹¤ìŒì€ ì‚¬ìš©ìì™€ AI í˜ë¥´ì†Œë‚˜ ê°„ì˜ ì†Œê°œíŒ… ëŒ€í™”ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ëŒ€í™” ìŠ¤í‚¬ì„ 'ì¹œê·¼í•¨', 'í˜¸ê¸°ì‹¬(ì§ˆë¬¸)', 'ê³µê°' ì„¸ ê°€ì§€ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ì¢…í•© ì ìˆ˜ì™€ í•¨ê»˜ êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”. ê²°ê³¼ëŠ” ì¹œì ˆí•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

    --- ëŒ€í™” ë‚´ìš© ---
    ${conversationText}
    --- ë¶„ì„ ì‹œì‘ ---
    
    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    {
      "totalScore": ëŒ€í™” ì „ì²´ì— ëŒ€í•œ 100ì  ë§Œì ì˜ ì¢…í•© ì ìˆ˜ (ì •ìˆ˜),
      "feedback": "ëŒ€í™” ì „ì²´ì— ëŒ€í•œ í•œ ì¤„ ìš”ì•½ í”¼ë“œë°±",
      "friendliness": {
        "score": ì¹œê·¼í•¨ í•­ëª© ì ìˆ˜ (1-100, ì •ìˆ˜),
        "feedback": "ì¹œê·¼í•¨ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°±"
      },
      "curiosity": {
        "score": í˜¸ê¸°ì‹¬(ì§ˆë¬¸) í•­ëª© ì ìˆ˜ (1-100, ì •ìˆ˜),
        "feedback": "í˜¸ê¸°ì‹¬(ì§ˆë¬¸)ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°±"
      },
      "empathy": {
        "score": ê³µê° ëŠ¥ë ¥ í•­ëª© ì ìˆ˜ (1-100, ì •ìˆ˜),
        "feedback": "ê³µê° ëŠ¥ë ¥ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°±"
      },
      "positivePoints": ["ëŒ€í™”ì—ì„œ ì˜í•œ ì  1", "ëŒ€í™”ì—ì„œ ì˜í•œ ì  2"],
      "pointsToImprove": [
        {
          "topic": "ê°œì„ í•  ì ì˜ ì£¼ì œ (ì˜ˆ: ì§ˆë¬¸ ë°©ì‹)",
          "suggestion": "êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ ë° ì˜ˆì‹œ"
        }
      ]
    }
    `

  try {
    const response = await openai.chat.completions.create({
      model: defaultModel,
      messages: [
        {
          role: "system",
          content: "You are an expert dating coach analyzing conversation skills. Always respond in valid JSON format."
        },
        { role: "user", content: prompt }
      ],
      temperature: 0.7,
      response_format: { type: "json_object" }
    })

    const jsonText = response.choices[0]?.message?.content || "{}"
    const analysisResult = JSON.parse(jsonText)
    return analysisResult as ConversationAnalysis
  } catch (error) {
    console.error("Error analyzing conversation:", error)
    return null
  }
}

export const getRealtimeFeedback = async (
  lastUserMessage: string,
  lastAiMessage: string | undefined
): Promise<RealtimeFeedback | null> => {
  if (!openai) return null

  // Only provide feedback occasionally to avoid annoyance
  if (Math.random() > 0.4) {
    return null
  }

  const prompt = `
    A user is in a dating conversation. Here is their last message and the AI's response to it.
    AI's last message: "${lastAiMessage || "ëŒ€í™” ì‹œì‘"}"
    User's message: "${lastUserMessage}"
    
    Analyze the user's message in context. Is it a good message (e.g., good question, good reaction, showing interest)? 
    Provide a very short, encouraging feedback or a tip in Korean (max 15 characters).
    
    Return the analysis in JSON format:
    {
      "isGood": true/false (boolean indicating if the message is positive),
      "message": "10ì ì´ë‚´ì˜ ì§§ì€ ê²©ë ¤ ë˜ëŠ” íŒ"
    }
    
    Example of good feedback: "ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”! ğŸ‘", "ê³µê°ê°€ëŠ” ë§ì´ë„¤ìš”! ğŸ˜Š"
    Example of a tip: "ë‹¤ë¥¸ ì£¼ì œë¡œ ë„˜ì–´ê°€ë³¼ê¹Œìš”? ğŸ’¡", "ì§ˆë¬¸ìœ¼ë¡œ ë‹µí•´ë³´ì„¸ìš”! ğŸ¤”"
    `

  try {
    const response = await openai.chat.completions.create({
      model: defaultModel,
      messages: [
        {
          role: "system",
          content: "You are a dating coach providing quick, encouraging feedback. Always respond in valid JSON format."
        },
        { role: "user", content: prompt }
      ],
      temperature: 0.8,
      max_tokens: 100,
      response_format: { type: "json_object" }
    })

    const jsonText = response.choices[0]?.message?.content || "{}"
    return JSON.parse(jsonText) as RealtimeFeedback
  } catch (error) {
    // Fail silently to not interrupt the chat flow
    console.error("Realtime feedback error:", error)
    return null
  }
}

export const getCoachSuggestion = async (
  conversation: Message[]
): Promise<{ reason: string; suggestion: string } | null> => {
  if (!openai) return null

  const conversationText = conversation
    .filter((msg) => msg.sender !== "system")
    .map((msg) => `${msg.sender === "user" ? "ë‚˜" : "ìƒëŒ€"}: ${msg.text}`)
    .join("\n")

  const prompt = `
    ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³ ì˜ ì—°ì•  ì½”ì¹˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” AI í˜ë¥´ì†Œë‚˜ì™€ ëŒ€í™” ì—°ìŠµì„ í•˜ë‹¤ê°€ ë‹¤ìŒì— ë¬´ìŠ¨ ë§ì„ í• ì§€ ë§‰íŒ ìƒí™©ì…ë‹ˆë‹¤.
    ì•„ë˜ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬, ì‚¬ìš©ìê°€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ë„ì›€ì´ ë˜ëŠ” ì œì•ˆì„ í•´ì£¼ì„¸ìš”.
    ì™œ ì´ ì œì•ˆì´ ì¢‹ì€ì§€ì— ëŒ€í•œ ì´ìœ ì™€ í•¨ê»˜, ì‹¤ì œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë©”ì‹œì§€ë¥¼ ì œì•ˆí•´ì•¼ í•©ë‹ˆë‹¤.
    
    --- í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ---
    ${conversationText}
    --------------------

    ì‚¬ìš©ìê°€ ë³´ë‚¸ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì´í›„ë¡œ ëŒ€í™”ê°€ ë§‰í˜”ìŠµë‹ˆë‹¤. 
    
    ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    {
      "reason": "ì‚¬ìš©ìê°€ ì™œ ë§‰í˜”ëŠ”ì§€, ì´ ì œì•ˆì´ ì™œ ì¢‹ì€ì§€ì— ëŒ€í•œ ê°„ë‹¨í•œ ì´ìœ  (í•œêµ­ì–´, 1-2 ë¬¸ì¥)",
      "suggestion": "ì‚¬ìš©ìê°€ ë‹¤ìŒìœ¼ë¡œ ë³´ë‚¼ ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ë©”ì‹œì§€ ì œì•ˆ (í•œêµ­ì–´)"
    }
    `

  try {
    const response = await openai.chat.completions.create({
      model: defaultModel,
      messages: [
        {
          role: "system",
          content: "You are an expert dating coach helping users with conversation skills. Always respond in valid JSON format."
        },
        { role: "user", content: prompt }
      ],
      temperature: 0.8,
      response_format: { type: "json_object" }
    })

    const jsonText = response.choices[0]?.message?.content || "{}"
    return JSON.parse(jsonText)
  } catch (error) {
    console.error("Error getting coach suggestion:", error)
    return null
  }
}

export const getStylingAdvice = async (
  prompt: string
): Promise<{ text: string; imageUrl: string | null }> => {
  if (!openai) {
    return {
      text: "AI ìŠ¤íƒ€ì¼ë§ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.",
      imageUrl: null
    }
  }

  try {
    // Get styling advice text
    const textResponse = await openai.chat.completions.create({
      model: defaultModel,
      messages: [
        {
          role: "system",
          content: "You are a professional fashion stylist. Provide styling advice that is specific, encouraging, and easy to understand. Respond in Korean."
        },
        {
          role: "user",
          content: `Provide styling advice for the following request: "${prompt}"`
        }
      ],
      temperature: 0.8,
      max_tokens: 500
    })

    const adviceText = textResponse.choices[0]?.message?.content || "ìŠ¤íƒ€ì¼ë§ ì¡°ì–¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    // Generate image using DALL-E 3
    try {
      const imageResponse = await openai.images.generate({
        model: "dall-e-3",
        prompt: `Fashion photography of a full-body outfit for: ${prompt}. Clean, bright, modern style. Show a person wearing the clothes. Professional fashion magazine style.`,
        n: 1,
        size: "1024x1792", // Tall format for fashion
        quality: "standard",
        style: "natural"
      })

      const imageUrl = imageResponse.data[0]?.url || null
      return { text: adviceText, imageUrl }
    } catch (imageError) {
      console.error("Error generating image:", imageError)
      // Return text advice even if image generation fails
      return { text: adviceText, imageUrl: null }
    }
  } catch (error) {
    console.error("Error getting styling advice:", error)
    return { text: "ìŠ¤íƒ€ì¼ë§ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", imageUrl: null }
  }
}

// Clean up chat sessions periodically to prevent memory leaks
setInterval(() => {
  const now = Date.now()
  const maxAge = 1000 * 60 * 60 // 1 hour
  
  // Note: In a real app, you'd track last access time for each session
  // For now, we'll just clear all sessions if there are too many
  if (chatSessions.size > 100) {
    const toDelete = chatSessions.size - 50
    const keys = Array.from(chatSessions.keys())
    for (let i = 0; i < toDelete; i++) {
      chatSessions.delete(keys[i])
    }
  }
}, 1000 * 60 * 10) // Every 10 minutes